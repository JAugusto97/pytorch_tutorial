{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uUN6OGI0Zq_m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "xiGCltrgd0Jv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.tensor(self.X[i], dtype=torch.float), torch.tensor(self.y[i], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ],
      "metadata": {
        "id": "spOlRMPfb0Nz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_iris(return_X_y=True)\n",
        "train_idxs, rest_idxs = train_test_split(range(len(y)), train_size=0.8)\n",
        "dev_idxs, test_idxs = train_test_split(rest_idxs, train_size=0.5)\n",
        "\n",
        "trainset = IrisDataset(X[train_idxs], y[train_idxs])\n",
        "devset = IrisDataset(X[dev_idxs], y[dev_idxs])\n",
        "testset = IrisDataset(X[test_idxs], y[test_idxs])"
      ],
      "metadata": {
        "id": "GZzcPkRkbwX8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(trainset, batch_size=8)\n",
        "dev_dataloader = DataLoader(devset, batch_size=8)\n",
        "test_dataloader = DataLoader(testset, batch_size=8)"
      ],
      "metadata": {
        "id": "a6dFHdFVYMPG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_stack = nn.Sequential(\n",
        "            nn.Linear(4, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        logits = self.linear_stack(X)\n",
        "        return logits\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        train_dataloader,\n",
        "        dev_dataloader=None,\n",
        "        num_epochs=50,\n",
        "        loss_fn=nn.CrossEntropyLoss,\n",
        "        optimizer=torch.optim.SGD,\n",
        "        lr=1e-2\n",
        "    ):\n",
        "        size = len(train_dataloader.dataset)\n",
        "        criterion = loss_fn()\n",
        "        optimizer = optimizer(self.parameters(), lr=lr)\n",
        "\n",
        "        self.to(device)\n",
        "        self.train()\n",
        "        num_batch = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            for X_batch, y_batch in train_dataloader:\n",
        "                batch_size = len(y_batch)\n",
        "\n",
        "                X_batch, y_true = X_batch.to(device), y_batch.to(device)\n",
        "    \n",
        "                logits = self(X_batch)\n",
        "                y_pred = nn.Softmax(dim=1)(logits)\n",
        "                loss = criterion(y_pred, y_true)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                loss, global_step, total_steps = loss.item(), num_batch * batch_size, size*num_epochs\n",
        "                num_batch += 1\n",
        "            \n",
        "            print(f\"epoch: {epoch}  loss: {loss:>7f}  batch: {global_step:5d}/{total_steps:>5d}\")\n",
        "            if dev_dataloader is not None:\n",
        "                self.score(dev_dataloader, loss_fn)\n",
        "                self.train()\n",
        "            print(\"\\n\")\n",
        "\n",
        "    def score(self, test_dataloader, loss_fn=nn.CrossEntropyLoss):\n",
        "        criterion = loss_fn()\n",
        "        self.eval()\n",
        "\n",
        "        num_batches = len(test_dataloader)\n",
        "        num_examples = len(test_dataloader.dataset)\n",
        "        test_loss, correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in test_dataloader:\n",
        "                X_batch, y_true = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "                logits = self(X_batch)\n",
        "                loss = criterion(logits, y_true)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                correct += (logits.argmax(dim=1) == y_true).sum().item()\n",
        "            \n",
        "        test_loss /= num_batches\n",
        "        correct /= num_examples\n",
        "        print(f\"Test Error Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")"
      ],
      "metadata": {
        "id": "FlrEhrIYaE76"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MyNet().to(device)\n",
        "clf.fit(train_dataloader, dev_dataloader, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb_lYlklSEUs",
        "outputId": "e0d8a48f-df6c-4389-ab65-a5eec56697b2"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  loss: 1.063545  batch:   112/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.958480\n",
            "\n",
            "\n",
            "epoch: 1  loss: 1.034826  batch:   232/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.931232\n",
            "\n",
            "\n",
            "epoch: 2  loss: 0.997870  batch:   352/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.913680\n",
            "\n",
            "\n",
            "epoch: 3  loss: 0.959804  batch:   472/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.894967\n",
            "\n",
            "\n",
            "epoch: 4  loss: 0.924299  batch:   592/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.875628\n",
            "\n",
            "\n",
            "epoch: 5  loss: 0.893409  batch:   712/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.853440\n",
            "\n",
            "\n",
            "epoch: 6  loss: 0.866690  batch:   832/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.825373\n",
            "\n",
            "\n",
            "epoch: 7  loss: 0.844457  batch:   952/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.793421\n",
            "\n",
            "\n",
            "epoch: 8  loss: 0.826744  batch:  1072/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.756622\n",
            "\n",
            "\n",
            "epoch: 9  loss: 0.811613  batch:  1192/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.716865\n",
            "\n",
            "\n",
            "epoch: 10  loss: 0.798147  batch:  1312/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.675214\n",
            "\n",
            "\n",
            "epoch: 11  loss: 0.785894  batch:  1432/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.634580\n",
            "\n",
            "\n",
            "epoch: 12  loss: 0.774457  batch:  1552/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.597042\n",
            "\n",
            "\n",
            "epoch: 13  loss: 0.763849  batch:  1672/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.564217\n",
            "\n",
            "\n",
            "epoch: 14  loss: 0.753990  batch:  1792/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.536222\n",
            "\n",
            "\n",
            "epoch: 15  loss: 0.744917  batch:  1912/12000\n",
            "Test Error Accuracy: 66.7%, Avg loss: 0.512137\n",
            "\n",
            "\n",
            "epoch: 16  loss: 0.736445  batch:  2032/12000\n",
            "Test Error Accuracy: 73.3%, Avg loss: 0.491477\n",
            "\n",
            "\n",
            "epoch: 17  loss: 0.728542  batch:  2152/12000\n",
            "Test Error Accuracy: 80.0%, Avg loss: 0.473052\n",
            "\n",
            "\n",
            "epoch: 18  loss: 0.721122  batch:  2272/12000\n",
            "Test Error Accuracy: 93.3%, Avg loss: 0.456783\n",
            "\n",
            "\n",
            "epoch: 19  loss: 0.714190  batch:  2392/12000\n",
            "Test Error Accuracy: 93.3%, Avg loss: 0.441791\n",
            "\n",
            "\n",
            "epoch: 20  loss: 0.707591  batch:  2512/12000\n",
            "Test Error Accuracy: 93.3%, Avg loss: 0.428422\n",
            "\n",
            "\n",
            "epoch: 21  loss: 0.701302  batch:  2632/12000\n",
            "Test Error Accuracy: 93.3%, Avg loss: 0.415948\n",
            "\n",
            "\n",
            "epoch: 22  loss: 0.695390  batch:  2752/12000\n",
            "Test Error Accuracy: 93.3%, Avg loss: 0.404140\n",
            "\n",
            "\n",
            "epoch: 23  loss: 0.689624  batch:  2872/12000\n",
            "Test Error Accuracy: 93.3%, Avg loss: 0.393357\n",
            "\n",
            "\n",
            "epoch: 24  loss: 0.684430  batch:  2992/12000\n",
            "Test Error Accuracy: 93.3%, Avg loss: 0.382971\n",
            "\n",
            "\n",
            "epoch: 25  loss: 0.679231  batch:  3112/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.373121\n",
            "\n",
            "\n",
            "epoch: 26  loss: 0.674263  batch:  3232/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.363604\n",
            "\n",
            "\n",
            "epoch: 27  loss: 0.669494  batch:  3352/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.354275\n",
            "\n",
            "\n",
            "epoch: 28  loss: 0.664925  batch:  3472/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.345294\n",
            "\n",
            "\n",
            "epoch: 29  loss: 0.660548  batch:  3592/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.336574\n",
            "\n",
            "\n",
            "epoch: 30  loss: 0.656303  batch:  3712/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.328157\n",
            "\n",
            "\n",
            "epoch: 31  loss: 0.652233  batch:  3832/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.320096\n",
            "\n",
            "\n",
            "epoch: 32  loss: 0.648322  batch:  3952/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.312082\n",
            "\n",
            "\n",
            "epoch: 33  loss: 0.644584  batch:  4072/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.304509\n",
            "\n",
            "\n",
            "epoch: 34  loss: 0.640963  batch:  4192/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.297061\n",
            "\n",
            "\n",
            "epoch: 35  loss: 0.637545  batch:  4312/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.289783\n",
            "\n",
            "\n",
            "epoch: 36  loss: 0.634227  batch:  4432/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.282689\n",
            "\n",
            "\n",
            "epoch: 37  loss: 0.630988  batch:  4552/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.276115\n",
            "\n",
            "\n",
            "epoch: 38  loss: 0.628045  batch:  4672/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.269392\n",
            "\n",
            "\n",
            "epoch: 39  loss: 0.625037  batch:  4792/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.263394\n",
            "\n",
            "\n",
            "epoch: 40  loss: 0.622374  batch:  4912/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.257118\n",
            "\n",
            "\n",
            "epoch: 41  loss: 0.619745  batch:  5032/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.251145\n",
            "\n",
            "\n",
            "epoch: 42  loss: 0.617227  batch:  5152/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.245499\n",
            "\n",
            "\n",
            "epoch: 43  loss: 0.614851  batch:  5272/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.240056\n",
            "\n",
            "\n",
            "epoch: 44  loss: 0.612528  batch:  5392/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.234725\n",
            "\n",
            "\n",
            "epoch: 45  loss: 0.610326  batch:  5512/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.229601\n",
            "\n",
            "\n",
            "epoch: 46  loss: 0.608239  batch:  5632/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.224647\n",
            "\n",
            "\n",
            "epoch: 47  loss: 0.606197  batch:  5752/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.219867\n",
            "\n",
            "\n",
            "epoch: 48  loss: 0.604196  batch:  5872/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.215429\n",
            "\n",
            "\n",
            "epoch: 49  loss: 0.602411  batch:  5992/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.210913\n",
            "\n",
            "\n",
            "epoch: 50  loss: 0.600617  batch:  6112/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.206781\n",
            "\n",
            "\n",
            "epoch: 51  loss: 0.598932  batch:  6232/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.202778\n",
            "\n",
            "\n",
            "epoch: 52  loss: 0.597344  batch:  6352/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.198855\n",
            "\n",
            "\n",
            "epoch: 53  loss: 0.595805  batch:  6472/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.195182\n",
            "\n",
            "\n",
            "epoch: 54  loss: 0.594362  batch:  6592/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.191616\n",
            "\n",
            "\n",
            "epoch: 55  loss: 0.592950  batch:  6712/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.188196\n",
            "\n",
            "\n",
            "epoch: 56  loss: 0.591615  batch:  6832/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.184917\n",
            "\n",
            "\n",
            "epoch: 57  loss: 0.590344  batch:  6952/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.181729\n",
            "\n",
            "\n",
            "epoch: 58  loss: 0.589128  batch:  7072/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.178627\n",
            "\n",
            "\n",
            "epoch: 59  loss: 0.587978  batch:  7192/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.175600\n",
            "\n",
            "\n",
            "epoch: 60  loss: 0.586868  batch:  7312/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.172828\n",
            "\n",
            "\n",
            "epoch: 61  loss: 0.585805  batch:  7432/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.169995\n",
            "\n",
            "\n",
            "epoch: 62  loss: 0.584776  batch:  7552/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.167332\n",
            "\n",
            "\n",
            "epoch: 63  loss: 0.583792  batch:  7672/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.164762\n",
            "\n",
            "\n",
            "epoch: 64  loss: 0.582851  batch:  7792/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.162233\n",
            "\n",
            "\n",
            "epoch: 65  loss: 0.581949  batch:  7912/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.159842\n",
            "\n",
            "\n",
            "epoch: 66  loss: 0.581083  batch:  8032/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.157509\n",
            "\n",
            "\n",
            "epoch: 67  loss: 0.580253  batch:  8152/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.155247\n",
            "\n",
            "\n",
            "epoch: 68  loss: 0.579458  batch:  8272/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.153064\n",
            "\n",
            "\n",
            "epoch: 69  loss: 0.578693  batch:  8392/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.150939\n",
            "\n",
            "\n",
            "epoch: 70  loss: 0.577958  batch:  8512/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.148940\n",
            "\n",
            "\n",
            "epoch: 71  loss: 0.577256  batch:  8632/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.146925\n",
            "\n",
            "\n",
            "epoch: 72  loss: 0.576577  batch:  8752/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.144934\n",
            "\n",
            "\n",
            "epoch: 73  loss: 0.575928  batch:  8872/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.143136\n",
            "\n",
            "\n",
            "epoch: 74  loss: 0.575306  batch:  8992/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.141332\n",
            "\n",
            "\n",
            "epoch: 75  loss: 0.574705  batch:  9112/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.139580\n",
            "\n",
            "\n",
            "epoch: 76  loss: 0.574124  batch:  9232/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.137867\n",
            "\n",
            "\n",
            "epoch: 77  loss: 0.573565  batch:  9352/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.136193\n",
            "\n",
            "\n",
            "epoch: 78  loss: 0.573029  batch:  9472/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.134583\n",
            "\n",
            "\n",
            "epoch: 79  loss: 0.572513  batch:  9592/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.133002\n",
            "\n",
            "\n",
            "epoch: 80  loss: 0.572015  batch:  9712/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.131470\n",
            "\n",
            "\n",
            "epoch: 81  loss: 0.571538  batch:  9832/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.129969\n",
            "\n",
            "\n",
            "epoch: 82  loss: 0.571078  batch:  9952/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.128518\n",
            "\n",
            "\n",
            "epoch: 83  loss: 0.570634  batch: 10072/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.127098\n",
            "\n",
            "\n",
            "epoch: 84  loss: 0.570205  batch: 10192/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.125708\n",
            "\n",
            "\n",
            "epoch: 85  loss: 0.569792  batch: 10312/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.124342\n",
            "\n",
            "\n",
            "epoch: 86  loss: 0.569392  batch: 10432/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.123022\n",
            "\n",
            "\n",
            "epoch: 87  loss: 0.569005  batch: 10552/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.121719\n",
            "\n",
            "\n",
            "epoch: 88  loss: 0.568631  batch: 10672/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.120445\n",
            "\n",
            "\n",
            "epoch: 89  loss: 0.568270  batch: 10792/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.119196\n",
            "\n",
            "\n",
            "epoch: 90  loss: 0.567920  batch: 10912/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.117973\n",
            "\n",
            "\n",
            "epoch: 91  loss: 0.567582  batch: 11032/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.116773\n",
            "\n",
            "\n",
            "epoch: 92  loss: 0.567260  batch: 11152/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.115589\n",
            "\n",
            "\n",
            "epoch: 93  loss: 0.566944  batch: 11272/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.114446\n",
            "\n",
            "\n",
            "epoch: 94  loss: 0.566642  batch: 11392/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.113314\n",
            "\n",
            "\n",
            "epoch: 95  loss: 0.566346  batch: 11512/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.112214\n",
            "\n",
            "\n",
            "epoch: 96  loss: 0.566059  batch: 11632/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.111137\n",
            "\n",
            "\n",
            "epoch: 97  loss: 0.565782  batch: 11752/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.110077\n",
            "\n",
            "\n",
            "epoch: 98  loss: 0.565512  batch: 11872/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.109036\n",
            "\n",
            "\n",
            "epoch: 99  loss: 0.565251  batch: 11992/12000\n",
            "Test Error Accuracy: 100.0%, Avg loss: 0.108013\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpK1w-j9XuFI",
        "outputId": "d539c69c-7ce5-4e99-dc01-e6e11a15084c"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error Accuracy: 86.7%, Avg loss: 0.291586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(clf.state_dict(), \"model.pt\")"
      ],
      "metadata": {
        "id": "pnpdnD7La75d"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ER3cFyQbBpl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}